#To build and train a model using human cell records, and classify cells to whether the samples are benign or malignant.

import pandas as pd
import pylab as pl
import numpy as np
import scipy.optimize as opt
from sklearn import preprocessing
from sklearn.model_selection import train_test_split
%matplotlib inline 
import matplotlib.pyplot as plt

"""
Load the Cancer data
The example is based on a dataset that is publicly available from the UCI Machine Learning Repository (Asuncion and Newman, 2007)
[http://mlearn.ics.uci.edu/MLRepository.html]. 
The dataset consists of several hundred human cell sample records, each of which contains the values of a set of cell characteristics.
"""

cell_df = pd.read_csv("cell_samples.csv")
cell_df.head()


#look at the distribution of the classes based on Clump thickness and Uniformity of cell size:
ax = cell_df[cell_df['Class'] == 4][0:50].plot(kind='scatter', x='Clump', y='UnifSize', color='DarkBlue', label='malignant');
cell_df[cell_df['Class'] == 2][0:50].plot(kind='scatter', x='Clump', y='UnifSize', color='Yellow', label='benign', ax=ax);
plt.show()

#Data pre-processing and selection

cell_df.dtypes
#the BareNuc column includes some values that are not numerical. We can drop those rows:
cell_df = cell_df[pd.to_numeric(cell_df['BareNuc'], errors='coerce').notnull()]
cell_df['BareNuc'] = cell_df['BareNuc'].astype('int')
cell_df.dtypes


feature_df = cell_df[['Clump', 'UnifSize', 'UnifShape', 'MargAdh', 'SingEpiSize', 'BareNuc', 'BlandChrom', 'NormNucl', 'Mit']]
X = np.asarray(feature_df)
X[0:5]

#We want the model to predict the value of Class (that is, benign (=2) or malignant (=4)). 
As this field can have one of only two possible values, we need to change its measurement level to reflect this.

cell_df['Class'] = cell_df['Class'].astype('int')
y = np.asarray(cell_df['Class'])
y [0:5]

X_train, X_test, y_train, y_test = train_test_split( X, y, test_size=0.2, random_state=4)
print ('Train set:', X_train.shape,  y_train.shape)
print ('Test set:', X_test.shape,  y_test.shape)


#Modeling (SVM with Scikit-learn)

from sklearn import svm
clf = svm.SVC(kernel='rbf')
clf.fit(X_train, y_train) 

yhat = clf.predict(X_test)
yhat [0:5]

#Evaluation

from sklearn.metrics import classification_report, confusion_matrix
import itertools

# Compute confusion matrix
cnf_matrix = confusion_matrix(y_test, yhat, labels=[2,4])
np.set_printoptions(precision=2)

print (classification_report(y_test, yhat))
"""
              precision    recall  f1-score   support

           2       1.00      0.94      0.97        90
           4       0.90      1.00      0.95        47

    accuracy                           0.96       137
   macro avg       0.95      0.97      0.96       137
weighted avg       0.97      0.96      0.96       137

[[85  5]
 [ 0 47]]

"""

from sklearn.metrics import f1_score
f1_score(y_test, yhat, average='weighted')  # 0.9639038982104676


#briefly and using another kernel function

clf1 = svm.SVC(kernel='linear')
clf1.fit(X_train, y_train) 
y_hat=clf1.predict(X_test)

f1_score(y_test,y_hat,average="weighted") 
print(f1_score(y_test,y_hat,average="weighted")) #0.9639038982104676
print(jaccard_score(y_test,y_hat,pos_label=2)) #0.9444444444444444
